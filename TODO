
TODO
----

(01) Esquemas de resolución iterativa

  b. Incorporar la idea de que el usuario pueda dar un subespacio inicial de
     búsqueda, por ejemplo con EPSSetInitialSpace. Analizar la relación con
     EPSSetInitialVector. Otra posibilidad es mantener la factorización
     internamente de una llamada EPSSolve a otra.

(04) Interfaces a paquetes externos

  b. Integrar Hlzpack en el mismo interfaz de Blzpack.

(06) Nuevos EPS

  b. Lanczos: Diversas versiones con diferentes
     técnicas de reortogonalización (parcial, selectiva, mixta). Revisar
     bibliografía e implementaciones (propack, blzpack, lanso, etc).

  c. Lanczos no simétrico: Algoritmo implementado en qmrpack.

  d. Davidson (y Davidson Generalizado al usar un precondicionado distinto
     de D_A).

  e. Jacobi-Davidson: basado en implementación de Sleijpen o de Hochstenbach.

  f. IRA/IRL: basado en implementación de Arpack (Fortran o Matlab) o de
     irbleigs (versión a bloques).

  g. Otros: ABLE, TRQ.

(07) Gestión de vectores de trabajo

  b. Ahorrar vectores de trabajo en EPSReverseProjection haciendo primero
     la descomposición QR.

(08) Utilidades

  b. Estructurar mejor la información que sacan los monitores por defecto.

(09) Test de convergencia

  a. Implementar una rutina ComputeRitzError análoga a EPSComputeRelativeError
     pero que haga el cálculo internamente en el solver con los valores no
     convergidos aún. Esta rutina sería genérica y la usarían todos los solvers
     salvo aquellos en los que se pueda obtener una estimación del error con 
     menos cálculos (p.e. Arnoldi). Convendría hacer una función virtual para
     esto? Para esto habría que unificar la representación interna de los
     valores/vectores de Ritz en todos los solvers.

  b. Rutinas del tipo SetConvergenceTest/DefaultConverged: analizar si podrían
     ser de interés para los solvers de valores propios.

(11) Métodos directos para los sistemas lineales

  a. Alternativa 1: Nuevo ST Cholesky, con OP=L^-1AL^T y BackTransform=L^Tx.
     Utilizaría MatCholeskyFactor, MatForwardSolve, MatBackwardSolve.

  b. Alternativa 2: Dos modos de trabajo: "split" (por defecto) e "inexact".
     En el primero se factoriza la matriz del sistema lineal y posteriormente
     se hacen los solves forward/backward (pro: más estabilidad numérica,
     contra: refactorizar cada vez que se cambia el shift). En el segundo
     se trabaja como hasta ahora, típicamente con solvers iterativos.
     Problema: para el modo split habría que disponer de factorizaciones de
     varios tipos: LU, LL^T y LDL^T. El modo split es análogo a 
     -ksp_symmetric_pc y éste parece que no está implementado del todo.

(12) Ortogonalización

  a. Posiblemente sea necesario tener dos rutinas de ortogonalización: p.e.
     EPSOrthogDeflate (elimina un vector si es linealmente dependiente 
     respecto de los demás) y EPSOrthogExpand (en ese caso crea un vector 
     aleatorio).

  b. Implementar una función que mida la calidad de la ortogonalización 
     (para debug, similar a la opción -pc_test_null_space).

(13) Problemas Relacionados

  a. Definir objetos nuevos para problemas relacionados, p.e. SVD (singular
     value decomposition), QEP (quadratic eigenvalue problem), NEP (non-linear
     eigenvalue problem), que tengan internamente un EPS.

  b. Suponemos que GHEP exige B Hermitiana definida positiva (es lo que se
     denomina definite matrix pencil). Si no es definida positiva hay que 
     sustituir B por alpha*A+beta*B siendo esta matrix definida positiva.
     Se supone que los parámetros alpha y beta se pueden calcular de forma
     automática (rutina pfind en http://www.netlib.org/toms/646, el problema
     es que es para matrices densas).

 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

BUGS
----



 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

DOCUMENTACION
-------------

